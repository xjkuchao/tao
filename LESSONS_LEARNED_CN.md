# 经验心得 (Lessons Learned)

本项目作为一个由人工智能完全自主驱动实现的纯 Rust 多媒体编解码框架实验，致力于记录在此探索过程中对市面上各种前端 AI 编程工具与大语言模型的真实使用感受和技术评价。

随着项目进度推进，我们将在此文件中持续追加记录。

### 关于工具与大模型的评价

_（待补充：未来开发过程中随时在此记录体会与心得...）_

2026年02月20日 18:01:20 - 接到执行类请求后应立即运行脚本, 并反馈可核对的具体结果(记录数, 输出文件名, 输出路径), 以避免沟通歧义。

2026年02月20日 18:04:15 - AI工具链在Linux环境下最高效。Windows下经常先调用rg、ls，再接管道|grep，报错后才发现是Windows环境，改用Get-Item等PowerShell语法，而且会反复降级。从经验看，最好在Linux下开发；Windows建议使用WSL，效果不错，能大幅减少工具调用错误后的重试。

2026年02月20日 18:40:09 - 目前我拥有: GitHub Pro 48USD/year, Copilot Pro 100USD/year, Cursor Pro 20USD/month, Google AI Pro 750THB/month, ChatGPT Pro 300SGD/month, Claude为企业账号(每个Standard子账号约240USD/月, 扣费方式不明, 超出Standard用量需额外付费)。评价下来: Claude的插件/CLI/Desktop在产品形态上最好用, 思考过程展示和长时间运行后的海量历史记录界面都很流畅; 但体感价格最贵, Standard在解码器算法调优场景下约3-4轮就会耗尽5小时额度, 另外开通15美元按量后, 一轮复杂调优也可能无法跑完。ChatGPT Pro是当前主力, 虽然价格高, 但连续跑复杂解码器调试时5小时用量通常不超过20%, 稳定性和可持续性较好。Cursor Pro在计划层面性价比高, Auto模式与API分开计费, 但连续4-5天高强度编码后两项额度都可能到100%, 随后需要等待到下月重置, 除非升级或开启Demand; 因已有ChatGPT Pro, 未继续为Cursor充值。GitHub/Copilot Pro主要配合VSCode使用, 但VSCode同样调用GPT或Claude模型, 因此整体使用频率较低。

2026年02月20日 18:44:37 - 今天Gemini 3.1刚发布, 正在配合Antigravity测试。Antigravity有独立的Agent Manager窗口, 这点很方便, 可以与Editor分开打开和切换; 但agent输出过程主要是英文, 思考过程可读性对中文用户不够友好。实测中, 使用Gemini 3.1对AAC解码器从98%精度做最后收尾, 很快达到100%精度; 目前还无法确定是模型能力显著提升, 还是样本与调参过程中的偶然因素。

2026年02月20日 18:49:53 - 此前使用GPT-5.2-Codex和Claude-4.6开发解码器时, 第一轮完成后对FFmpeg导出的标准音频样本进行测试, 基本全军覆没, 首次测试精度几乎都不超过10%。之后通常需要反复把结果喂给AI自行调试, 体感上有一定碰运气成分。第一个复杂解码器是MPEG-4 Part 2, 当时多种AI轮换投入约2-3天, 精度仍长期上不去, 一度怀疑AI是否能胜任该类任务; 同时首次制定计划并执行也带来较多反复。后续继续做MP3和Vorbis解码器明显提速。现在通常只需一句话: 以Vorbis为模板制定XXX解码器开发计划, 再提供1.xx和2.xx两个样本, 就可以让AI持续推进。由此看, AI更擅长在已有且完善的工作流中重复执行; 而首次制定全新计划时, 很难一次做到完善。

2026年02月20日 18:56:16 - Claude在处理Vorbis精度提升时曾持续报错: Response过大并反复失败。排查后确认是思考过程过于复杂, 超过最大回包量; 通过设置环境变量 export CLAUDE_CODE_MAX_OUTPUT_TOKENS=64000 解决。从另一个侧面看, token可能大量消耗在思考过程输出上。在该阶段我对思考过程本身并不敏感, 但计费成本是实打实发生的。
